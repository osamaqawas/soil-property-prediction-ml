"""
Author: Osama Alqawasmeh
Project: Hyperspectral-Based Soil Contamination Prediction
Institute: Yarmouk University, Jordan

Model: XGBoost Regressor for Predicting Soil Iron (Fe)
"""

# =========================================================
# 1. Import libraries
# =========================================================

import pandas as pd
import numpy as np
from xgboost import XGBRegressor
from sklearn.model_selection import train_test_split, cross_validate
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import matplotlib.pyplot as plt
import seaborn as sns
import os


# =========================================================
# 2. Load dataset
# =========================================================

def load_data(path="data/Fe.xlsx"):
    """
    Load Excel dataset containing environmental and spectral variables.
    """
    return pd.read_excel(path)


# =========================================================
# 3. Train XGBoost model
# =========================================================

def train_xgboost(df):
    """
    Train an XGBoost regression model to predict Fe concentration.
    """

    # Select input features
    features = [
        'pH', 'Slope', 'Carbonate', 'Clay %', 'OM %',
        'Elevation', 'SiO2', 'Al2O3', 'NDVI',
        'Dis_Water', 'Dis_Station'
    ]

    X = df[features]
    y = df['Fe']

    # Optional: StandardScaler
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # Train-test split
    X_train, X_test, y_train, y_test = train_test_split(
        X_scaled, y, test_size=0.2, random_state=54
    )

    # Initialize model
    model = XGBRegressor(
        n_estimators=100,
        learning_rate=0.1,
        max_depth=3,
        random_state=42
    )

    # Train model
    model.fit(X_train, y_train)

    # Predictions
    y_pred = model.predict(X_test)

    # Metrics
    metrics = {
        "r2": r2_score(y_test, y_pred),
        "rmse": mean_squared_error(y_test, y_pred, squared=False),
        "mae": mean_absolute_error(y_test, y_pred)
    }

    print("\nHoldout Test Set Evaluation:")
    print(f"R² Score:  {metrics['r2']:.3f}")
    print(f"RMSE:      {metrics['rmse']:.2f}")
    print(f"MAE:       {metrics['mae']:.2f}")

    return model, scaler, X, X_scaled, y, y_test, y_pred, features


# =========================================================
# 4. Cross-Validation
# =========================================================

def cross_validation(model, X_scaled, y):
    """
    Perform 5-fold cross-validation on the trained model.
    """

    cv_results = cross_validate(
        model,
        X_scaled,
        y,
        cv=5,
        scoring=('r2', 'neg_root_mean_squared_error', 'neg_mean_absolute_error'),
        return_train_score=False
    )

    print("\n5-Fold Cross-Validation Results:")
    print(f"Avg R²:   {cv_results['test_r2'].mean():.3f}")
    print(f"Avg RMSE: {-cv_results['test_neg_root_mean_squared_error'].mean():.2f}")
    print(f"Avg MAE:  {-cv_results['test_neg_mean_absolute_error'].mean():.2f}")


# =========================================================
# 5. Plotting Functions
# =========================================================

def plot_feature_importance(model, features, save_path="figures/feature_importance.png"):
    """
    Save a barplot of XGBoost feature importance.
    """

    os.makedirs(os.path.dirname(save_path), exist_ok=True)

    importances = model.feature_importances_
    sorted_idx = np.argsort(importances)[::-1]

    plt.figure(figsize=(10, 6))
    sns.barplot(x=importances[sorted_idx], y=np.array(features)[sorted_idx])
    plt.title("Feature Importance - XGBoost")
    plt.xlabel("Importance Score")
    plt.tight_layout()
    plt.savefig(save_path)
    plt.close()


def plot_actual_vs_predicted(y_test, y_pred, save_path="figures/actual_vs_predicted.png"):
    """
    Save scatter plot of actual vs predicted Fe.
    """

    os.makedirs(os.path.dirname(save_path), exist_ok=True)

    plt.figure(figsize=(6, 6))
    sns.scatterplot(x=y_test, y=y_pred)
    plt.xlabel('Actual Fe')
    plt.ylabel('Predicted Fe')
    plt.title('XGBoost: Actual vs Predicted')
    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
    plt.grid(True)
    plt.tight_layout()
    plt.savefig(save_path)
    plt.close()


# =========================================================
# 6. Main execution
# =========================================================

if __name__ == "__main__":
    df = load_data()
    model, scaler, X, X_scaled, y, y_test, y_pred, features = train_xgboost(df)
    cross_validation(model, X_scaled, y)
    plot_feature_importance(model, features)
    plot_actual_vs_predicted(y_test, y_pred)

    print("\nAll tasks completed successfully.")
